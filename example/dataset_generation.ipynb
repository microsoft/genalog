{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Dataset Generation\n",
    "\n",
    "Here we demonstrate how to use our `genalog` package to generate synthetic documents with custom image degradation and upload the documents to an Azure Blob Storage.\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"static/labeled_synthetic_pipeline.png\" width=\"900\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset file structure \n",
    "\n",
    "Our dataset follows this file structure:\n",
    "```\n",
    "<ROOT FOLDER>/                             #eg. synthetic-image-root\n",
    "     <SRC_DATASET_NAME>                    #eg. CNN-Dailymail-Stories\n",
    "        │\n",
    "        │───shared/                        #common files shared across different dataset versions\n",
    "        │     │───train/\n",
    "        │     │     │───clean_text/  \n",
    "        │     │     │     │─0.txt\n",
    "        │     │     │     │─1.txt\n",
    "        │     │     │     └─...\n",
    "        │     │     └───clean_labels/\n",
    "        │     │           │─0.txt\n",
    "        │     │           │─1.txt\n",
    "        │     │           └─...\n",
    "        │     └───test/\n",
    "        │           │───clean_text/*.txt\n",
    "        │           └───clean_labels/*.txt\n",
    "        │   \n",
    "        └───<VERSION_NAME>/                #e.g. hyphens_blur_heavy\n",
    "               │───train/\n",
    "               │     │─img/*.png           #Degraded Images\n",
    "               │     │─ocr/*.json          #json output files that are output of GROK\n",
    "               │     │─ocr_text/*.txt      #text output retrieved from OCR Json Files\n",
    "               │     └─ocr_labels/*.txt    #Aligned labels files in IOB format\n",
    "               │───test/\n",
    "               │     │─img/*.png           #Degraded Images\n",
    "               │     │─ocr/*.json          #json output files that are output of GROK\n",
    "               │     │─ocr_text/*.txt      #text output retrieved from OCR Json Files\n",
    "               │     └─ocr_labels/*.txt    #Aligned labels files in IOB format\n",
    "               │\n",
    "               │───layout.json             #records page layout info (font-family,template name, etc)\n",
    "               │───degradation.json        #records degradation parameters\n",
    "               │───ocr_metric.csv          #records metrics on OCR noise across the dataset\n",
    "               └───substitution.json       #records character substitution errors in the OCR'ed text.\n",
    "```"
   ]
  },
  {
   "source": [
    "## Source NER Dataset\n",
    "\n",
    "This pipeline is designed to work with standard NER datasets like CoNLL 2003 and CoNLL 2012. You can downaload the source dataset from DeepAI: [CoNLL-2003](https://deepai.org/dataset/conll-2003-english)\n",
    "\n",
    "**NOTE:** the source dataset has three separate columns of NER labels, we are only interested in the last column:\n",
    "\n",
    "```\n",
    "       Source                                Desired (space-separted)\n",
    "\n",
    "DOCSTART- -X- -X- O                        DOCSTART O\n",
    "SOCCER NN B-NP O                           SOCCER O\n",
    "- : O O                                    - O\n",
    "JAPAN NNP B-NP B-LOC                       JAPAN B-LOC\n",
    "GET VB B-VP O                              GET O\n",
    "LUCKY NNP B-NP O                           LUCKY O\n",
    "WIN NNP I-NP O                             WIN O\n",
    ", , O O                                    , O\n",
    "CHINA NNP B-NP B-PER                       CHINA B-PER\n",
    "IN IN B-PP O                               IN O\n",
    "SURPRISE DT B-NP O                         SURPRISE O\n",
    "DEFEAT NN I-NP O                           DEFEAT O\n",
    "...                                        ...\n",
    "```\n",
    "\n",
    "Unfortunately, this preprocess step is out of the scope of this pipeline.\n",
    "\n",
    "**TODO:** Add support for this or share the preprocessed dataset.\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Dataset Split\n",
    "\n",
    "Before we can generate analog documents, we need text to populate the analog documents. To do so, we will split the source text into smaller text fragments. Here we have provided a script `genalog.text.splitter` to easily split NER datasets CoNLL-2003 and CoNLL-2012 in the following ways:\n",
    "\n",
    "1. **Split dataset into smaller fragments**: each fragment is named as `<INDEX>.txt`\n",
    "1. **Separate NER labels from document text**: NER labels will be stored in `clean_lables` folder and text in `clean_text` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE_TEMPLATE = \"/data/enki/datasets/CoNLL_2003_2012/CoNLL-<DATASET_YEAR>/CoNLL-<DATASET_YEAR>_<SUBSET>.txt\"\n",
    "OUTPUT_FOLDER_TEMPLATE = \"/data/enki/datasets/synthetic_dataset/CoNLL_<DATASET_YEAR>_v3/shared/<SUBSET>/\"\n",
    "for year in [\"2003\", \"2012\"]:\n",
    "    for subset in [\"test\", \"train\"]:\n",
    "        # INPUT_FILE = \"/data/enki/datasets/CoNLL_2003_2012/CoNLL-2012/CoNLL-2012_test.txt\"\n",
    "        INPUT_FILE = INPUT_FILE_TEMPLATE.replace(\"<DATASET_YEAR>\", year).replace(\"<SUBSET>\", subset)\n",
    "        # OUTPUT_FOLDER = \"/data/enki/datasets/synthetic_dataset/CoNLL_2012_v2/shared/test/\"\n",
    "        OUTPUT_FOLDER = OUTPUT_FOLDER_TEMPLATE.replace(\"<DATASET_YEAR>\", year).replace(\"<SUBSET>\", subset)\n",
    "        \n",
    "        print(f\"Loading {INPUT_FILE} \\nOutput to {OUTPUT_FOLDER}\")\n",
    "        if year == \"2003\":\n",
    "            !python -m genalog.text.splitter $INPUT_FILE $OUTPUT_FOLDER --doc_sep=\"-DOCSTART-\\tO\"\n",
    "        else:\n",
    "            !python -m genalog.text.splitter $INPUT_FILE $OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations\n",
    "We will generate the synthetic dataset on your local disk first. You will need to specify the following CONSTANTS to locate where to store the dataset:\n",
    "\n",
    "1. `ROOT_FOLDER`: root directory of the dataset, path can be relative to the location of this notebook.\n",
    "1. `SRC_DATASET_NAME`: name of the source dataset from which the text used in the generation originates from\n",
    "1. `SRC_TRAIN_SPLIT_PATH`: path of the train-split of the source dataset\n",
    "1. `SRC_TEST_SPLIT_PATH`: path of the test-split of the source dataset\n",
    "1. `VERSION_NAME`: version name of the generated dataset\n",
    "\n",
    "You will also have to define the styles and degradation effects you will like to apply onto each generated document:\n",
    " \n",
    "1. `STYLE_COMBINATIONS`: a dictionary defining the combination of styles to generate per text document (i.e. a copy of the same text document is generate per style combination). Example is shown below:\n",
    "\n",
    "        STYLE_COMBINATION = {\n",
    "        \"language\": [\"en_US\"],\n",
    "        \"font_family\": [\"Segoe UI\"],\n",
    "        \"font_size\": [\"12px\"],\n",
    "        \"text_align\": [\"left\"],\n",
    "        \"hyphenate\": [False],\n",
    "        }\n",
    "    \n",
    "    You can expand the list of each style for more combinations\n",
    "    \n",
    "    \n",
    "2. `DEGRADATIONS`: a list defining the sequence of degradation effects applied onto the synthetic images. Each element is a two-element tuple of which the first element is one of the method names from  `genalog.degradation.effect` and the second element is the corresponding function keyword arguments.\n",
    "\n",
    "        DEGRADATIONS = [\n",
    "            (\"blur\", {\"radius\": 3}),\n",
    "            (\"bleed_through\", {\"alpha\": 0.8}),\n",
    "            (\"morphology\", {\"operation\": \"open\", \"kernel_shape\": (3,3), \"kernel_type\": \"ones\"}), \n",
    "        ]\n",
    "    The example above will apply degradation effects to synthetic images in the sequence of: \n",
    "    \n",
    "            blur -> bleed_through -> morphological operation (open)\n",
    "    \n",
    "   \n",
    "3. `HTML_TEMPLATE`: name of html template used to generate the synthetic images. The `genalog` package has the following default templates: \n",
    "\n",
    "    1. `columns.html.jinja` \n",
    "    2. `letter.html.jinja`\n",
    "    3. `text_block.html.jinja`\n",
    "    \n",
    "            HTML_TEMPLATE = 'text_block.html.jinja'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genalog.degradation.degrader import ImageState\n",
    "\n",
    "ROOT_FOLDER = \"/data/enki/datasets/synthetic_dataset/\"\n",
    "SRC_DATASET_NAME = \"CoNLL_2003_v3\"\n",
    "VERSION_NAME = \"hyphens_close_heavy\"\n",
    "SRC_TRAIN_SPLIT_PATH = ROOT_FOLDER + SRC_DATASET_NAME + \"/shared/train/clean_text/\"\n",
    "SRC_TEST_SPLIT_PATH = ROOT_FOLDER + SRC_DATASET_NAME + \"/shared/test/clean_text/\"\n",
    "DST_TRAIN_PATH = ROOT_FOLDER + SRC_DATASET_NAME + \"/\" + VERSION_NAME + \"/train/\"\n",
    "DST_TEST_PATH = ROOT_FOLDER + SRC_DATASET_NAME + \"/\" + VERSION_NAME + \"/test/\"\n",
    "\n",
    "STYLE_COMBINATIONS = {\n",
    "    \"language\": [\"en_US\"],\n",
    "     \"font_family\": [\"Segeo UI\"],\n",
    "     \"font_size\": [\"12px\"],\n",
    "     \"text_align\": [\"justify\"],\n",
    "     \"hyphenate\": [True],\n",
    "}\n",
    "\n",
    "DEGRADATIONS = [\n",
    "## Stacking Degradations\n",
    "    (\"morphology\", {\"operation\": \"open\", \"kernel_shape\":(9,9), \"kernel_type\":\"plus\"}),\n",
    "    (\"morphology\", {\"operation\": \"close\", \"kernel_shape\":(9,1), \"kernel_type\":\"ones\"}),\n",
    "    (\"salt\", {\"amount\": 0.9}),\n",
    "    (\"overlay\", {\n",
    "        \"src\": ImageState.ORIGINAL_STATE,\n",
    "        \"background\": ImageState.CURRENT_STATE,\n",
    "    }),\n",
    "    (\"bleed_through\", {\n",
    "        \"src\": ImageState.CURRENT_STATE,\n",
    "        \"background\": ImageState.ORIGINAL_STATE,\n",
    "        \"alpha\": 0.95,\n",
    "        \"offset_x\": -6,\n",
    "        \"offset_y\": -12,\n",
    "    }),\n",
    "    (\"pepper\", {\"amount\": 0.001}),\n",
    "    (\"blur\", {\"radius\": 5}),\n",
    "    (\"salt\", {\"amount\": 0.1}),\n",
    "]\n",
    "\n",
    "HTML_TEMPLATE = \"text_block.html.jinja\"\n",
    "\n",
    "IMG_RESOLUTION = 300 #dpi\n",
    "\n",
    "print(f\"Training set will be saved to: '{DST_TRAIN_PATH}'\")\n",
    "print(f\"Testing set will be saved to: '{DST_TEST_PATH}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Text Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "train_text = sorted(glob.glob(SRC_TRAIN_SPLIT_PATH + \"*.txt\"))\n",
    "test_text = sorted(glob.glob(SRC_TEST_SPLIT_PATH + \"*.txt\"))\n",
    "\n",
    "print(f\"Number of training text documents: {len(train_text)}\")\n",
    "print(f\"Number of testing text documents: {len(test_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from genalog.pipeline import AnalogDocumentGeneration\n",
    "from IPython.core.display import Image, display\n",
    "import timeit\n",
    "import cv2\n",
    "\n",
    "sample_file = test_text[0]\n",
    "print(f\"Sample Filename: {sample_file}\")\n",
    "doc_generation = AnalogDocumentGeneration(styles=STYLE_COMBINATIONS, degradations=DEGRADATIONS, resolution=IMG_RESOLUTION)\n",
    "print(f\"Avaliable Templates: {doc_generation.list_templates()}\")\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "img_array = doc_generation.generate_img(sample_file, HTML_TEMPLATE, target_folder=None)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(f\"Time to generate 1 documents: {elapsed:.3f} sec\")\n",
    "\n",
    "_, encoded_image = cv2.imencode('.png', img_array)\n",
    "display(Image(data=encoded_image, width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from genalog.pipeline import generate_dataset_multiprocess\n",
    "\n",
    "# Generating test set\n",
    "generate_dataset_multiprocess(\n",
    "    test_text, DST_TEST_PATH, STYLE_COMBINATIONS, DEGRADATIONS, HTML_TEMPLATE, \n",
    "    resolution=IMG_RESOLUTION, batch_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genalog.pipeline import generate_dataset_multiprocess\n",
    "\n",
    "# Generating training set\n",
    "generate_dataset_multiprocess(\n",
    "    train_text, DST_TRAIN_PATH, STYLE_COMBINATIONS, DEGRADATIONS, HTML_TEMPLATE, \n",
    "    resolution=IMG_RESOLUTION, batch_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Dataset Configurations as .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genalog.pipeline import ImageStateEncoder\n",
    "import json\n",
    "\n",
    "layout_json_path = ROOT_FOLDER + SRC_DATASET_NAME + \"/\" + VERSION_NAME + \"/layout.json\"\n",
    "degradation_json_path = ROOT_FOLDER + SRC_DATASET_NAME + \"/\" + VERSION_NAME + \"/degradation.json\"\n",
    "\n",
    "layout = {\n",
    "    \"style_combinations\": STYLE_COMBINATIONS,\n",
    "    \"img_resolution\": IMG_RESOLUTION,\n",
    "    \"html_templates\": [HTML_TEMPLATE],\n",
    "}\n",
    "\n",
    "layout_js_str = json.dumps(layout, indent=2)\n",
    "degrade_js_str = json.dumps(DEGRADATIONS, indent=2, cls=ImageStateEncoder)\n",
    "\n",
    "with open(layout_json_path, \"w\") as f:\n",
    "    f.write(layout_js_str)\n",
    "    \n",
    "with open(degradation_json_path, \"w\") as f:\n",
    "    f.write(degrade_js_str)\n",
    "    \n",
    "print(f\"Writing configs to {layout_json_path}\")\n",
    "print(f\"Writing configs to {degradation_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Azure Blob Client\n",
    "\n",
    "We will use Azure Cognitive Service to run OCR on these synthetic images, and we will first upload the dataset to blob storage.\n",
    "\n",
    "1. If you haven't already, setup new Azure resources \n",
    "    1. [Azure Blob Storage](https://azure.microsoft.com/en-us/services/storage/blobs/) (for storage)\n",
    "    1. [Azure Cognitive Search](https://azure.microsoft.com/en-us/services/search/) (for OCR results)\n",
    "1. Create an `.secret` file with the environment variables that includes the names of you index, indexer, skillset, and datasource to create on the search service. Include keys to the blob that contains the documents you want to index, keys to the congnitive service and keys to you computer vision subscription and search service. In order to index more than 20 documents, you must have a computer services subscription. An example of one such `.secret` file is below:\n",
    "\n",
    "    ```bash\n",
    "\n",
    "    SEARCH_SERVICE_NAME = \"ocr-ner-pipeline\"\n",
    "    SKILLSET_NAME = \"ocrskillset\"\n",
    "    INDEX_NAME = \"ocrindex\"\n",
    "    INDEXER_NAME = \"ocrindexer\"\n",
    "    DATASOURCE_NAME = <BLOB STORAGE ACCOUNT NAME>\n",
    "    DATASOURCE_CONTAINER_NAME = <BLOB CONTAINER NAME>\n",
    "    \n",
    "    COMPUTER_VISION_ENDPOINT = \"https://<YOUR ENDPOINT NAME>.cognitiveservices.azure.com/\"\n",
    "    COMPUTER_VISION_SUBSCRIPTION_KEY = \"<YOUR SUBSCRIPTION KEY>\"\n",
    "    \n",
    "    BLOB_NAME = \"<YOUR BLOB STORAGE NAME>\"\n",
    "    BLOB_KEY = \"<YOUR BLOB KEY>\"\n",
    "    SEARCH_SERVICE_KEY = \"<YOUR SEARCH SERVICE KEY>\"\n",
    "    COGNITIVE_SERVICE_KEY = \"<YOUR COGNITIVE SERVICE KEY>\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from genalog.ocr.blob_client import GrokBlobClient\n",
    "\n",
    "# Setup variables and authenticate blob client\n",
    "ROOT_FOLDER = \"/data/enki/datasets/synthetic_dataset/\"\n",
    "SRC_DATASET_NAME = \"CoNLL_2012_v3\"\n",
    "\n",
    "local_path = ROOT_FOLDER + SRC_DATASET_NAME \n",
    "remote_path = SRC_DATASET_NAME\n",
    "\n",
    "print(f\"Uploadig from local_path: {local_path}\")\n",
    "print(f\"Upload to remote_path:    {remote_path}\")\n",
    "\n",
    "load_dotenv(\"../.secrets\")\n",
    "\n",
    "blob_client = GrokBlobClient.create_from_env_var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Dataset to Azure Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# Python uploads can be slow.\n",
    "# for very large datasets use azcopy: https://github.com/Azure/azure-storage-azcopy\n",
    "start = time.time()\n",
    "dest, res = blob_client.upload_images_to_blob(local_path, remote_path, use_async=True)\n",
    "await res\n",
    "print(\"time (mins): \", (time.time()-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a remote folder on Blob\n",
    "# blob_client.delete_blobs_folder(\"CoNLL_2003_v2_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Indexer and Retrieve OCR results\n",
    "Please note that this process can take a **long time**, but you can upload multiple dataset to Blob and run this once for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from genalog.ocr.rest_client import GrokRestClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.secrets\")\n",
    "grok_rest_client = GrokRestClient.create_from_env_var()\n",
    "grok_rest_client.create_indexing_pipeline()\n",
    "grok_rest_client.run_indexer()\n",
    "\n",
    "# wait for indexer to finish\n",
    "grok_rest_client.poll_indexer_till_complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download OCR Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Downloading multiple dataset to local\n",
    "remote_path = SRC_DATASET_NAME\n",
    "local_path = ROOT_FOLDER + SRC_DATASET_NAME\n",
    "versions = [\"hyphens_all_heavy\"]\n",
    "version_prefix = \"\"\n",
    "version_suffixes = [\"\"]\n",
    "print(f\"Remote Path: {remote_path} \\nLocal Path: {local_path} \\nVersions: {versions}\")\n",
    "\n",
    "blob_img_paths_test = []\n",
    "blob_img_paths_train = []\n",
    "local_ocr_json_paths_test = []\n",
    "local_ocr_json_paths_train = []\n",
    "version_name = \"\"\n",
    "for version in versions:\n",
    "    for weight in version_suffixes:\n",
    "        version_name = version_prefix + version + weight\n",
    "        blob_img_paths_test.append(os.path.join(remote_path, version_name, \"test\", \"img\"))\n",
    "        blob_img_paths_train.append(os.path.join(remote_path, version_name, \"train\", \"img\"))\n",
    "        local_ocr_json_paths_test.append(os.path.join(local_path, version_name, \"test\", \"ocr\"))\n",
    "        local_ocr_json_paths_train.append(os.path.join(local_path, version_name, \"train\", \"ocr\"))\n",
    "print(f\"Example Version Name: {version_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download OCR\n",
    "for blob_path_test, blob_path_train, local_path_test, local_path_train in \\\n",
    "    zip(blob_img_paths_test, blob_img_paths_train, \\\n",
    "        local_ocr_json_paths_test, local_ocr_json_paths_train):\n",
    "        \n",
    "    print(f\"Downloading \\nfrom remote path:'{blob_path_test} \\n   to local path:'{local_path_test}'\")\n",
    "    await blob_client.get_ocr_json(blob_path_test, output_folder=local_path_test, use_async=True)\n",
    "    print(f\"Downloading \\nfrom remote path:'{blob_path_train} \\n   to local path:'{local_path_train}'\")\n",
    "    await blob_client.get_ocr_json(blob_path_train, output_folder=local_path_train, use_async=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate OCR metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "local_path = ROOT_FOLDER + SRC_DATASET_NAME\n",
    "versions = [\"hyphens_all_heavy\"]\n",
    "version_prefix = \"\"\n",
    "version_suffixes = [\"\"]\n",
    "print(f\"Local Path: {local_path} \\nVersions: {versions}\\n\")\n",
    "\n",
    "input_json_path_templates = []\n",
    "output_metric_path = []\n",
    "for version in versions:\n",
    "    for suffix in version_suffixes:\n",
    "        version_name = version_prefix + version + suffix\n",
    "        # Location depends on the input dataset\n",
    "        input_json_path_templates.append(os.path.join(local_path, version_name, \"<test/train>/ocr\"))\n",
    "        output_metric_path.append(os.path.join(local_path, version_name))\n",
    "        \n",
    "clean_text_path_template = os.path.join(local_path, \"shared/<test/train>/clean_text\")\n",
    "csv_metric_name_template = \"<test/train>_ocr_metrics.csv\"\n",
    "subs_json_name_template = \"<test/train>_subtitutions.json\"\n",
    "avg_metric_name = \"ocr_metrics.csv\"\n",
    "\n",
    "print(f\"Loading \\n'{clean_text_path_template}' \\nand \\n'{input_json_path_templates[0]}'...\")\n",
    "print(f\"Saving to {output_metric_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from genalog.ocr.metrics import get_metrics, substitution_dict_to_json\n",
    "\n",
    "for input_json_path_template, output_metric_path in zip(input_json_path_templates, output_metric_path):\n",
    "    subsets = [\"train\", \"test\"]\n",
    "    avg_stat = {subset: None for subset in subsets}\n",
    "    for subset in subsets:\n",
    "        clean_text_path = clean_text_path_template.replace(\"<test/train>\", subset)\n",
    "        ocr_json_path = input_json_path_template.replace(\"<test/train>\", subset)\n",
    "        csv_metric_name = csv_metric_name_template.replace(\"<test/train>\", subset)\n",
    "        subs_json_name = subs_json_name_template.replace(\"<test/train>\", subset)\n",
    "\n",
    "        output_csv_name = output_metric_path + \"/\" + csv_metric_name\n",
    "        output_json_name = output_metric_path + \"/\" + subs_json_name\n",
    "\n",
    "        print(f\"Saving to '{output_csv_name}' \\nand '{output_json_name}'\")\n",
    "        df, subs, actions = get_metrics(clean_text_path, ocr_json_path, use_multiprocessing=True)\n",
    "        # Writing metrics on individual file\n",
    "        df.to_csv(output_csv_name)\n",
    "        json.dump(substitution_dict_to_json(subs), open(output_json_name, \"w\"))\n",
    "        # Getting average metrics\n",
    "        avg_stat[subset] = df.mean()\n",
    "\n",
    "    # Saving average metrics\n",
    "    avg_stat = pd.DataFrame(avg_stat)\n",
    "    output_avg_csv = os.path.join(output_metric_path, avg_metric_name)\n",
    "    avg_stat.to_csv(output_avg_csv)\n",
    "    print(f\"Saving average metrics to {output_avg_csv}\")\n",
    "    print(avg_stat[16:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize OCR'ed Text into IOB Format For Model Training Purpose\n",
    "\n",
    "The last step in preparing the dataset is to format all the OCR'ed text and the NER label into a usable format for training. Our model consume data in IOB format, which is the same format used in the CoNLL datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/data/enki/datasets/synthetic_dataset/CoNLL_2012_v3\"\n",
    "versions = [\"hyphens_all_heavy\"]\n",
    "version_prefix = \"\"\n",
    "version_suffixes = [\"\"]\n",
    "version_names = []\n",
    "for version in versions:\n",
    "    for suffix in version_suffixes:\n",
    "        version_names.append(version_prefix + version + suffix)\n",
    "print(f\"base_path: {base_path}\\nversion_names: {version_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in version_names:\n",
    "    !python -m genalog.text.conll_format $base_path $version --train_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Re-upload Local Dataset to Blob \n",
    "\n",
    "We can re-upload the local copy of the dataset to Blob Storage to sync up the two copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "local_dataset_to_sync = os.path.join(local_path)\n",
    "blob_path = os.path.join(remote_path)\n",
    "print(f\"local_dataset_to_sync: {local_dataset_to_sync}\\nblob_path: {blob_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Python uploads can be slow.\n",
    "# for very large datasets use azcopy: https://github.com/Azure/azure-storage-azcopy\n",
    "start = time.time()\n",
    "dest, res = blob_client.upload_images_to_blob(local_dataset_to_sync, blob_path, use_async=True)\n",
    "await res\n",
    "print(\"time (mins): \", (time.time()-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}